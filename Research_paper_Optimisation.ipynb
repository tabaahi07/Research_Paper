{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN54E7xOFkNUUNF3dj620H4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tabaahi07/Research_Paper/blob/main/Research_paper_Optimisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y7F6gripspYJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "XM8UrhHrtD2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747df434-4a83-40e5-997c-f6840b7df114"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to range [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, 28 * 28))\n",
        "X_test_scaled = scaler.transform(X_test.reshape(-1, 28 * 28))"
      ],
      "metadata": {
        "id": "epxiQvS3tM7y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning for SVM\n",
        "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "svm = GridSearchCV(SVC(), param_grid, refit=True, verbose=2)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "print(\"SVM Accuracy: \", accuracy_score(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M7nVsw3tPQU",
        "outputId": "f1ff98ce-9178-4d8c-9b6c-cce4491b3f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV] END ...............................C=0.1, kernel=linear; total time= 2.9min\n",
            "[CV] END ...............................C=0.1, kernel=linear; total time= 2.9min\n",
            "[CV] END ...............................C=0.1, kernel=linear; total time= 2.9min\n",
            "[CV] END ...............................C=0.1, kernel=linear; total time= 2.8min\n",
            "[CV] END ...............................C=0.1, kernel=linear; total time= 2.9min\n",
            "[CV] END ..................................C=0.1, kernel=rbf; total time= 9.2min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest with PCA for dimensionality reduction\n",
        "pca = PCA(n_components=100)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_pca, y_train)\n",
        "y_pred_rf = rf.predict(X_test_pca)\n",
        "print(\"Random Forest Accuracy: \", accuracy_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "ZN6tILrctRa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "10b1ac9d-7459-4cc9-82e6-1a13ad670e85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PCA' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4fbeb4090ea4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Random Forest with PCA for dimensionality reduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PCA' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning using VGG16 for CNN\n",
        "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(28, 28, 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(vgg)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=5, validation_data=(X_test.reshape(-1, 28, 28, 1), y_test))\n",
        "\n",
        "y_pred_cnn = np.argmax(model.predict(X_test.reshape(-1, 28, 28, 1)), axis=-1)\n",
        "print(\"CNN with Transfer Learning Accuracy: \", accuracy_score(y_test, y_pred_cnn))"
      ],
      "metadata": {
        "id": "t21yTqn7tVZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate all models\n",
        "results = {\n",
        "    'SVM': {\n",
        "        'accuracy': accuracy_score(y_test, y_pred_svm),\n",
        "        'f1_score': f1_score(y_test, y_pred_svm, average='weighted'),\n",
        "        'precision': precision_score(y_test, y_pred_svm, average='weighted'),\n",
        "        'recall': recall_score(y_test, y_pred_svm, average='weighted')\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'accuracy': accuracy_score(y_test, y_pred_rf),\n",
        "        'f1_score': f1_score(y_test, y_pred_rf, average='weighted'),\n",
        "        'precision': precision_score(y_test, y_pred_rf, average='weighted'),\n",
        "        'recall': recall_score(y_test, y_pred_rf, average='weighted')\n",
        "    },\n",
        "    'CNN with Transfer Learning': {\n",
        "        'accuracy': accuracy_score(y_test, y_pred_cnn),\n",
        "        'f1_score': f1_score(y_test, y_pred_cnn, average='weighted'),\n",
        "        'precision': precision_score(y_test, y_pred_cnn, average='weighted'),\n",
        "        'recall': recall_score(y_test, y_pred_cnn, average='weighted')\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "NyJFpE7dtasd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "import tabulate\n",
        "table = [[model, metrics['accuracy'], metrics['f1_score'], metrics['precision'], metrics['recall']] for model, metrics in results.items()]\n",
        "print(tabulate.tabulate(table, headers=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall'], tablefmt='grid'))"
      ],
      "metadata": {
        "id": "cUtfCRpRtdfr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}